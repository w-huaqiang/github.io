<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>华强的技术小站</title>
  
  <subtitle>知行合一</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://huaqiang.art/"/>
  <updated>2020-04-04T11:00:07.772Z</updated>
  <id>http://huaqiang.art/</id>
  
  <author>
    <name>王华强</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>helm安装openldap</title>
    <link href="http://huaqiang.art/2020/04/01/openldap/"/>
    <id>http://huaqiang.art/2020/04/01/openldap/</id>
    <published>2020-04-01T14:54:12.000Z</published>
    <updated>2020-04-04T11:00:07.772Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>OpenLDAP是轻型目录访问协议（Lightweight Directory Access Protocol，LDAP）的自由和开源的实现，在其OpenLDAP许可证下发行，并已经被包含在众多流行的Linux发行版中。如果你理解微软的AD，那么他将提供和AD类似的功能。</p><a id="more"></a><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><img src="/assets/img/openldap.jpg" width="80%"><h3 id="openLDAP-server配置"><a href="#openLDAP-server配置" class="headerlink" title="openLDAP server配置"></a>openLDAP server配置</h3><h4 id="cert-manager生成证书"><a href="#cert-manager生成证书" class="headerlink" title="cert-manager生成证书"></a>cert-manager生成证书</h4><p>CA证书生成过程可以参考cert-manager中CA部分,此处直接通过CA的issuer创建服务器所需的certificates，其中<code>secretName</code>后面会用到，<code>commonName</code>可以写ldap server的域名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ cat openldap-server-cert.yaml</span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Certificate</span><br><span class="line">metadata:</span><br><span class="line">  name: hq-opnldap1</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  secretName: hq-openldap1</span><br><span class="line">  issuerRef:</span><br><span class="line">    name: ca-issuer</span><br><span class="line">    kind: Issuer</span><br><span class="line">  commonName: hqopenldap.com</span><br><span class="line">$ kubectl apply -f openldap-server-cert.yaml</span><br></pre></td></tr></table></figure><h4 id="helm安装openldap"><a href="#helm安装openldap" class="headerlink" title="helm安装openldap"></a>helm安装openldap</h4><ul><li>检查是否包含openldap的helm仓库，仓库地址为：<a href="http://mirror.azure.cn/kubernetes/charts/">http://mirror.azure.cn/kubernetes/charts/</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo list</span><br><span class="line">NAME         URL                                                                      </span><br><span class="line">stable       http://mirror.azure.cn/kubernetes/charts/                                </span><br><span class="line"><span class="built_in">local</span>        http://127.0.0.1:8879/charts                                             </span><br><span class="line">ali-incubatorhttps://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/</span><br><span class="line">ali-stable   https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts                   </span><br><span class="line">jetstack     https://charts.jetstack.io</span><br></pre></td></tr></table></figure><blockquote><p>注意：若没有则添加仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add stable http://mirror.azure.cn/kubernetes/charts/</span><br></pre></td></tr></table></figure></blockquote><ul><li>查找openldap chart，并下载到本地</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm search openldap</span><br><span class="line">NAME           CHART VERSIONAPP VERSIONDESCRIPTION                      </span><br><span class="line">stable/openldap1.2.3        2.4.48     Community developed LDAP software</span><br><span class="line">$ helm fetch stable/openldap</span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line">$  tar -xzvf openldap-1.2.3.tgz</span><br></pre></td></tr></table></figure><ul><li>修改chart中的values.yaml文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> openldap</span><br><span class="line">$ cat values.yaml |grep -v <span class="string">'^ *#'</span>|grep -v <span class="string">'^$'</span></span><br><span class="line">replicaCount: 1</span><br><span class="line">strategy: &#123;&#125;</span><br><span class="line">image:</span><br><span class="line">  repository: osixia/openldap</span><br><span class="line">  tag: 1.2.4</span><br><span class="line">  pullPolicy: IfNotPresent</span><br><span class="line">existingSecret: <span class="string">""</span></span><br><span class="line">tls:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  secret: <span class="string">"hq-openldap1"</span>  <span class="comment"># The name of a kubernetes.io/tls type secret to use for TLS</span></span><br><span class="line">  CA:</span><br><span class="line">    enabled: <span class="literal">false</span></span><br><span class="line">    secret: <span class="string">"ca-key-pair"</span>  <span class="comment"># The name of a generic secret to use for custom CA certificate (ca.crt)</span></span><br><span class="line">extraLabels: &#123;&#125;</span><br><span class="line">podAnnotations: &#123;&#125;</span><br><span class="line">service:</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">  clusterIP: <span class="string">""</span></span><br><span class="line">  ldapPort: 389</span><br><span class="line">  sslLdapPort: 636  <span class="comment"># Only used if tls.enabled is true</span></span><br><span class="line">  externalIPs: []</span><br><span class="line">  loadBalancerIP: <span class="string">""</span></span><br><span class="line">  loadBalancerSourceRanges: []</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">env:</span><br><span class="line">  LDAP_ORGANISATION: <span class="string">"Example Inc."</span></span><br><span class="line">  LDAP_DOMAIN: <span class="string">"stopenldap.com"</span></span><br><span class="line">  LDAP_BACKEND: <span class="string">"hdb"</span></span><br><span class="line">  LDAP_TLS: <span class="string">"true"</span></span><br><span class="line">  LDAP_TLS_ENFORCE: <span class="string">"false"</span></span><br><span class="line">  LDAP_REMOVE_CONFIG_AFTER_SETUP: <span class="string">"true"</span></span><br><span class="line">adminPassword: admin</span><br><span class="line">configPassword: config</span><br><span class="line">persistence:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  accessMode: ReadWriteOnce</span><br><span class="line">  size: 2Gi</span><br><span class="line">resources: &#123;&#125;</span><br><span class="line">initResources: &#123;&#125;</span><br><span class="line">nodeSelector: </span><br><span class="line">  run: openldap</span><br><span class="line">tolerations: []</span><br><span class="line">affinity: &#123;&#125;</span><br><span class="line"><span class="built_in">test</span>:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  image:</span><br><span class="line">    repository: dduportal/bats</span><br><span class="line">    tag: 0.4.0</span><br></pre></td></tr></table></figure><p>主要修改的地方有：1.<code>tls.enabled: true</code>     启动tls认证</p><p>​                                   2.<code>tls.secret: hq-openldap1</code>   tls认证证书的secret，为cert-manager生成<code>secertNAME</code></p><p>​                                   3.<code>env.LDAP_DOMAIN: &quot;stopenldap.com&quot;</code> ldap DN名称</p><p>​                                   4.<code>adminPassword: admin</code>  admin的密码</p><p>​                                   5.<code>configPassword: config</code>  config的密码</p><p>​                                   6.<code>persistence.enabled:true</code>  设置持久化存储，默认时候default storageclass</p><p>​                                   7. <code>persistence.size:2G</code> 持久化存储大小</p><ul><li>安装</li></ul><p>在当前目录下执行helm install安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --name hqopenldap --namespace default .</span><br></pre></td></tr></table></figure><blockquote><p><code>* 快速安装 *</code><br>如果不想本地保存chart，而是直接安装则可执行以下命令,其中env.LDAP_TLS_VERIFY_CLIENT=try表示client可以没有证书。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;$ helm install --name hqopenldap \</span><br><span class="line">&gt;--namespace default \</span><br><span class="line">&gt;--<span class="built_in">set</span> tls.enabled=<span class="literal">true</span> \</span><br><span class="line">&gt;--<span class="built_in">set</span> tls.secret=hq-openldap1 \</span><br><span class="line">&gt;--<span class="built_in">set</span> env.LDAP_DOMAIN=stopenldap.com \</span><br><span class="line">&gt;--<span class="built_in">set</span> adminPassword=admin \</span><br><span class="line">&gt;--<span class="built_in">set</span> configPassword=config \</span><br><span class="line">&gt;--<span class="built_in">set</span> persistence.enabled=<span class="literal">true</span> \</span><br><span class="line">&gt;--<span class="built_in">set</span> persistence.size=2Gi \</span><br><span class="line">&gt;--<span class="built_in">set</span> env.LDAP_TLS_VERIFY_CLIENT=try \</span><br><span class="line">&gt;stable/openldap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">检查是否启动成功</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">$ kubectl get pod -l app=openldap</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">hqopenldap-85d59d49b4-6jl7c   1/1     Running   0          138m </span><br></pre></td></tr></table></figure></blockquote><h3 id="客户端测试"><a href="#客户端测试" class="headerlink" title="客户端测试"></a>客户端测试</h3><h4 id="签发客户端所需的证书和私钥"><a href="#签发客户端所需的证书和私钥" class="headerlink" title="签发客户端所需的证书和私钥"></a>签发客户端所需的证书和私钥</h4><p>此处所使用的CA issuer和ldap server中所使用的CA需要为同一个,<code>commonName</code>可以自行定义，不同客户取名不同</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ cat client-cert.yaml</span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Certificate</span><br><span class="line">metadata:</span><br><span class="line">  name: openldap-client1</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  secretName: client-test1</span><br><span class="line">  issuerRef:</span><br><span class="line">    name: ca-issuer</span><br><span class="line">    kind: Issuer</span><br><span class="line">  commonName: ldapadmin</span><br></pre></td></tr></table></figure><h4 id="导出证书文件"><a href="#导出证书文件" class="headerlink" title="导出证书文件"></a>导出证书文件</h4><p>由于测试是使用本地安装的LDAP Admin Tool，所有需要把k8s中生成的证书文件拿下来</p><ul><li>导出证书</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get secret/client-test1 -o jsonpath=<span class="string">"&#123;['data']['tls\.crt']&#125;"</span>|base64 --decode &gt; ldap.crt</span><br></pre></td></tr></table></figure><ul><li>导出私钥</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get secret/client-test1 -o jsonpath=<span class="string">"&#123;['data']['tls\.key']&#125;"</span>|base64 --decode &gt; ldap.key</span><br></pre></td></tr></table></figure><blockquote><p>注意: 由于LDAP Admin Tool使用的私钥为pkcs#8，所以需要将私钥转换下</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ openssl pkcs8 -topk8 -inform PEM -<span class="keyword">in</span> ldap.key -outform pem -nocrypt -out ldap.pem</span><br></pre></td></tr></table></figure><h4 id="LDAP-Admin-Tool连接"><a href="#LDAP-Admin-Tool连接" class="headerlink" title="LDAP Admin Tool连接"></a>LDAP Admin Tool连接</h4><ul><li>导入证书和私钥</li></ul><p><code>Security</code>-&gt;<code>manage client certificates</code>-&gt;<code>Add Certificate</code>   导入证书</p><p><code>Security</code>-&gt;<code>manage client certificates</code>-&gt;鼠标选中证书-<code>Set Private Key</code> 导入私钥</p><ul><li>连接LDAP server</li></ul><p>连接信息中：Base DN: dc=stopenldap,dc=com    参照helm <code>values.yaml</code>中<code>env.LDAP_DOMAIN</code></p><p>​                       User DN: cn=admin,dc=stopenldap,dc=com 参照helm <code>values.yaml</code>中<code>env.LDAP_DOMAIN</code></p><p>​                       Port: 636</p><p>​                       Password: admin       参照helm <code>values.yaml</code>中<code>adminPassword</code></p><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>ldap server启动TLS时，默认需要验证client端的证书，若不想给客户端签发证书,可通过设置server端不验证证书即可，可以通过添加values.yaml中的一个参数设置:<code>env.LDAP_TLS_VERIFY_CLIENT: &quot;try&quot;</code></p><blockquote><p>never：不验证客户端证书。</p><p>allow：检查客户端证书，没有证书或证书错误，都允许连接。</p><p>try：检查客户端证书，没有证书（允许连接），证书错误（终止连接）。</p><p>demand | hard | true：检查客户端证书，没有证书或证书错误都将立即终止连接。</p><p>helm 安装的openldap默认为demand。</p></blockquote>]]></content>
    
    <summary type="html">
    
      通过certmanager管理openldap证书，开启openLDAP TLS模式
    
    </summary>
    
    
      <category term="k8s" scheme="http://huaqiang.art/categories/k8s/"/>
    
    
      <category term="openLDAP" scheme="http://huaqiang.art/tags/openLDAP/"/>
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="cert-manager" scheme="http://huaqiang.art/tags/cert-manager/"/>
    
  </entry>
  
  <entry>
    <title>k8s证书管理cert-manager</title>
    <link href="http://huaqiang.art/2020/03/28/cert-manager/"/>
    <id>http://huaqiang.art/2020/03/28/cert-manager/</id>
    <published>2020-03-28T11:32:22.000Z</published>
    <updated>2020-04-04T09:53:20.008Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>cert-manager是kubernetes原生证书解决方案，可以通过多种机构颁发证书，证书最后以secret的形式存储在kubernetes中。可以支持Let’s encrypt，self signed，CA等。</p><a id="more"></a><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><img src="/assets/img/cert-manager.jpg" width="75%"><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="创建资源"><a href="#创建资源" class="headerlink" title="创建资源"></a>创建资源</h4><ul><li>创建crd</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Kubernetes 1.15+</span></span><br><span class="line">$ kubectl apply --validate=<span class="literal">false</span> -f https://github.com/jetstack/cert-manager/releases/download/v0.14.0/cert-manager.crds.yaml</span><br></pre></td></tr></table></figure><ul><li>helm安装</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加helm repo</span></span><br><span class="line">$ helm repo add jetstack https://charts.jetstack.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># Helm v3+</span></span><br><span class="line">$ helm install \</span><br><span class="line">  cert-manager jetstack/cert-manager \</span><br><span class="line">  --namespace cert-manager \</span><br><span class="line">  --version v0.14.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Helm v2</span></span><br><span class="line">$ helm install \</span><br><span class="line">  --name cert-manager \</span><br><span class="line">  --namespace cert-manager \</span><br><span class="line">  --version v0.14.0 \</span><br><span class="line">  jetstack/cert-manager</span><br></pre></td></tr></table></figure><h4 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n cert-manager</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">cert-manager-845c74ff94-5mdkk              1/1     Running   0          5h15m</span><br><span class="line">cert-manager-cainjector-648dd444df-h7jh5   1/1     Running   0          5h15m</span><br><span class="line">cert-manager-webhook-6dbcd48f9c-shh7z      1/1     Running   0          5h15m</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="CA"><a href="#CA" class="headerlink" title="CA"></a>CA</h4><p>手动创建根证书和私钥，或者从其他地方获取根证书及私钥。将证书存储在k8s的secret中，用来颁发证书，可以用内部的CA证书信任生成的签名证书。</p><h5 id="创建根证书"><a href="#创建根证书" class="headerlink" title="创建根证书"></a>创建根证书</h5><ul><li>openssl生成密钥及证书</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ openssl genrsa -out ca.key 2048</span><br><span class="line">$ openssl req -x509 -new -nodes -key ca.key -subj <span class="string">"/CN=hqtest"</span> -days 3650 -reqexts v3_req -extensions v3_ca -out ca.crt</span><br></pre></td></tr></table></figure><ul><li>导入k8s的secret</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create secret tls ca-key-pair \</span><br><span class="line">   --cert=ca.crt \</span><br><span class="line">   --key=ca.key \</span><br><span class="line">   --namespace=default</span><br></pre></td></tr></table></figure><h5 id="创建签发机构"><a href="#创建签发机构" class="headerlink" title="创建签发机构"></a>创建签发机构</h5><ul><li><p>创建issuer,</p><p>Issuer 只能用来签发自己所在 namespace 下的证书，ClusterIssuer 可以签发任意 namespace 下的证书,类似k8s中role和clusterrole</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat issuer.yaml </span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Issuer</span><br><span class="line">metadata:</span><br><span class="line">  name: ca-issuer</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  ca:</span><br><span class="line">    secretName: ca-key-pair</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f issuer.yaml</span><br></pre></td></tr></table></figure><h5 id="创建证书"><a href="#创建证书" class="headerlink" title="创建证书"></a>创建证书</h5><ul><li><p>创建certtificate</p><p>cert-manager 给提供了 Certificate 这个用于生成证书的自定义资源对象，但它必须在某个namespace下</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cat certs.yaml </span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Certificate</span><br><span class="line">metadata:</span><br><span class="line">  name: example-com</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  secretName: example-com-tls</span><br><span class="line">  issuerRef:</span><br><span class="line">    name: ca-issuer</span><br><span class="line">    kind: Issuer</span><br><span class="line">  commonName: ning.com</span><br><span class="line">  organization:</span><br><span class="line">  - CA</span><br><span class="line">  dnsNames:</span><br><span class="line">  - ning.com</span><br><span class="line">  - nginx.ning.com</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f certs.yaml</span><br></pre></td></tr></table></figure><h5 id="ingress使用证书"><a href="#ingress使用证书" class="headerlink" title="ingress使用证书"></a>ingress使用证书</h5><ul><li>创建一个nginx例子</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">$ cat nginx.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: my-nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: my-nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: my-nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: my-nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: my-nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">    name: http</span><br><span class="line">  selector:</span><br><span class="line">    run: my-nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: my-nginx</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: <span class="string">"nginx"</span></span><br><span class="line">    kubernetes.io/tls-acme: <span class="string">"true"</span></span><br><span class="line">    certmanager.k8s.io/issuer: <span class="string">"ca-issuer"</span></span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: nginx.ning.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          serviceName: my-nginx</span><br><span class="line">          servicePort: 80</span><br><span class="line">        path: /</span><br><span class="line">  tls:</span><br><span class="line">  - secretName: nginx-secret</span><br><span class="line">    hosts:</span><br><span class="line">    - nginx.ning.com</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure><h4 id="自签名证书"><a href="#自签名证书" class="headerlink" title="自签名证书"></a>自签名证书</h4><h5 id="创建自签名证书Issuer"><a href="#创建自签名证书Issuer" class="headerlink" title="创建自签名证书Issuer"></a>创建自签名证书Issuer</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ cat cert-resource.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: cert-manager-test</span><br><span class="line">---</span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Issuer</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="built_in">test</span>-selfsigned</span><br><span class="line">  namespace: cert-manager-test</span><br><span class="line">spec:</span><br><span class="line">  selfSigned: &#123;&#125;</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f cert-resource.yaml</span><br></pre></td></tr></table></figure><h5 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a><span id="jump">生成证书</span></h5><ul><li>手动生成</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ cat certificate-example-com.yaml</span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: Certificate</span><br><span class="line">metadata:</span><br><span class="line">  name: selfsigned-cert</span><br><span class="line">  namespace: cert-manager-test</span><br><span class="line">spec:</span><br><span class="line">  dnsNames:</span><br><span class="line">    - example.com</span><br><span class="line">  secretName: selfsigned-cert-tls</span><br><span class="line">  issuerRef:</span><br><span class="line">    name: <span class="built_in">test</span>-selfsigned</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f certificate-example-com.yaml</span><br></pre></td></tr></table></figure><ul><li>自动生成</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 selfsigne]<span class="comment"># cat nginx-self.yaml </span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-deploy</span><br><span class="line">  namespace: cert-manager-test</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myapp</span><br><span class="line">      release: canary</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myapp</span><br><span class="line">        release: canary</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: myapp</span><br><span class="line">        image: ikubernetes/myapp:v1</span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp</span><br><span class="line">  namespace: cert-manager-test</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">    release: canary</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80 </span><br><span class="line">    targetPort: 80 <span class="comment"># pod port</span></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-myapp</span><br><span class="line">  namespace: cert-manager-test</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: nginx</span><br><span class="line">    cert-manager.io/issuer: <span class="built_in">test</span>-selfsigned</span><br><span class="line">    kubernetes.io/tls-acme: <span class="string">"true"</span></span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: myapp.self.tech</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: myapp</span><br><span class="line">          servicePort: 80</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - myapp.self.tech</span><br><span class="line">    secretName: myapp</span><br></pre></td></tr></table></figure><p>​    创建资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx-self.yaml</span><br></pre></td></tr></table></figure><blockquote><p>注意: 1. 自动创建证书中，标记ingress参数metadata.annotations.cert-manager.io/issuer: test-selfsigned,test-selfsigned为issuer名称</p><pre><code>2. 若使用clusterissuer则参数为 metadata.annotations.cert-manager.io/cluster-issuer</code></pre></blockquote><h4 id="letsencrypt"><a href="#letsencrypt" class="headerlink" title="letsencrypt"></a>letsencrypt</h4><h5 id="创建资源clusterissuer"><a href="#创建资源clusterissuer" class="headerlink" title="创建资源clusterissuer"></a>创建资源clusterissuer</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat clusterissuer.yaml </span><br><span class="line">apiVersion: cert-manager.io/v1alpha2</span><br><span class="line">kind: ClusterIssuer</span><br><span class="line">metadata:</span><br><span class="line">  name: letsencrypt-prod</span><br><span class="line">spec:</span><br><span class="line">  acme:</span><br><span class="line">    server: https://acme-v02.api.letsencrypt.org/directory</span><br><span class="line">    email: 845789131@qq.com</span><br><span class="line">    privateKeySecretRef:</span><br><span class="line">      name: letsencrypt-prod</span><br><span class="line">    solvers:</span><br><span class="line">    - http01:</span><br><span class="line">        ingress:</span><br><span class="line">          class: nginx</span><br></pre></td></tr></table></figure><h5 id="生成证书-1"><a href="#生成证书-1" class="headerlink" title="生成证书"></a>生成证书</h5><p>生成证书方式和其他方式类似，可手动生成，也可以ingress自动生成，参考上节<a href="#jump">生成证书</a></p><blockquote><p>注意：1.letsencrypt通过acme协议自动申请证书，其中包含两个sloving Challenge: http01,dns01,主要用来证明域名是属于你所有。</p><ol start="2"><li>http01的校验原理是给你域名指向的 HTTP 服务增加一个临时 location ，<code>Let’s Encrypt</code> 会发送 http 请求到 <code>http:///.well-known/acme-challenge/</code>，<code>YOUR_DOMAIN</code> 就是被校验的域名，<code>TOKEN</code>是 ACME 协议的客户端负责放置的文件，在这里 ACME 客户端就是 cert-manager，它通过修改 Ingress 规则来增加这个临时校验路径并指向提供 <code>TOKEN</code> 的服务。此方法仅适用于给使用 Ingress 暴露流量的服务颁发证书，并且不支持泛域名证书。</li><li>dns01 的校验原理是利用 DNS 提供商的 API Key 拿到你的 DNS 控制权限， 在 Let’s Encrypt 为 ACME 客户端提供令牌后，ACME 客户端 (cert-manager) 将创建从该令牌和您的帐户密钥派生的 TXT 记录，并将该记录放在 <code>_acme-challenge.</code>。 然后 Let’s Encrypt 将向 DNS 系统查询该记录，如果找到匹配项，就可以颁发证书。此方法不需要你的服务使用 Ingress，并且支持泛域名证书。</li></ol><p>​            </p></blockquote><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><ul><li>查看ingress-controller访问方式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc -n ingress-nginx</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.233.21.195   &lt;none&gt;        80:30773/TCP,443:30762/TCP   13d</span><br></pre></td></tr></table></figure><ul><li>添加 /etc/hosts解析（若有内部DNS，可配置DNS）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/hosts</span><br><span class="line">3.1.20.110 nginx.ning.com</span><br></pre></td></tr></table></figure><blockquote><p>注意：由于ingress-controller是nodeport暴露方式，这里需要写k8s其中一个node的IP</p></blockquote><ul><li>访问url</li></ul><p>浏览器打开访问：<a href="https://nginx.ning.com:30762">https://nginx.ning.com:30762</a></p><blockquote><p>注意：此处端口为ingress-controller暴露的443的nodeport端口，而非80</p></blockquote><p>官网介绍： <a href="https://cert-manager.io/docs/configuration/acme/">https://cert-manager.io/docs/configuration/acme/</a></p>]]></content>
    
    <summary type="html">
    
      k8s证书管理软件
    
    </summary>
    
    
      <category term="k8s" scheme="http://huaqiang.art/categories/k8s/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="cert-manager" scheme="http://huaqiang.art/tags/cert-manager/"/>
    
  </entry>
  
  <entry>
    <title>rook使用cephfs</title>
    <link href="http://huaqiang.art/2020/02/17/rook-cephfs/"/>
    <id>http://huaqiang.art/2020/02/17/rook-cephfs/</id>
    <published>2020-02-17T12:36:21.000Z</published>
    <updated>2020-04-04T07:37:24.295Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul><li>默认安装好了kubernetes集群</li><li>默认已经安装好了rook,安装rook参考上篇<code>rook安装及使用ceph rbd</code><a id="more"></a></br></li><li><input checked="" disabled="" type="checkbox"> 注意: k8s out tree存储有两种方式csi及flexvolume，此文件使用flexvolume，不过csi才是未来。</li></ul><h2 id="创建文件系统"><a href="#创建文件系统" class="headerlink" title="创建文件系统"></a>创建文件系统</h2><p>编排文件如下<code>filesystem.yaml</code>,其中failureDomain为host且replicated是3时，则osd至少在3个主机上，即ceph至少需要三个存储主机。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">CephFilesystem</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">myfs</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># The metadata pool spec. Must use replication.</span></span><br><span class="line"><span class="attr">  metadataPool:</span></span><br><span class="line"><span class="attr">    replicated:</span></span><br><span class="line"><span class="attr">      size:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment"># The list of data pool specs. Can use replication or erasure coding.</span></span><br><span class="line"><span class="attr">  dataPools:</span></span><br><span class="line"><span class="attr">    - failureDomain:</span> <span class="string">host</span></span><br><span class="line"><span class="attr">      replicated:</span></span><br><span class="line"><span class="attr">        size:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment"># The metadata service (mds) configuration</span></span><br><span class="line"><span class="attr">  metadataServer:</span></span><br><span class="line">    <span class="comment"># The number of active MDS instances</span></span><br><span class="line"><span class="attr">    activeCount:</span> <span class="number">1</span></span><br><span class="line">    <span class="comment"># Whether each active MDS instance will have an active standby with a warm metadata cache for faster failover.</span></span><br><span class="line">    <span class="comment"># If false, standbys will be available, but will not have a warm cache.</span></span><br><span class="line"><span class="attr">    activeStandby:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># The affinity rules to apply to the mds deployment</span></span><br><span class="line"><span class="attr">    placement:</span></span><br><span class="line">    <span class="comment">#  nodeAffinity:</span></span><br><span class="line">    <span class="comment">#    requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">    <span class="comment">#      nodeSelectorTerms:</span></span><br><span class="line">    <span class="comment">#      - matchExpressions:</span></span><br><span class="line">    <span class="comment">#        - key: role</span></span><br><span class="line">    <span class="comment">#          operator: In</span></span><br><span class="line">    <span class="comment">#          values:</span></span><br><span class="line">    <span class="comment">#          - mds-node</span></span><br><span class="line">    <span class="comment">#  tolerations:</span></span><br><span class="line">    <span class="comment">#  - key: mds-node</span></span><br><span class="line">    <span class="comment">#    operator: Exists</span></span><br><span class="line">    <span class="comment">#  podAffinity:</span></span><br><span class="line">    <span class="comment">#  podAntiAffinity:</span></span><br><span class="line">    <span class="comment"># A key/value list of annotations</span></span><br><span class="line"><span class="attr">    annotations:</span></span><br><span class="line">    <span class="comment">#  key: value</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line">    <span class="comment"># The requests and limits set here, allow the filesystem MDS Pod(s) to use half of one CPU core and 1 gigabyte of memory</span></span><br><span class="line">    <span class="comment">#  limits:</span></span><br><span class="line">    <span class="comment">#    cpu: "500m"</span></span><br><span class="line">    <span class="comment">#    memory: "1024Mi"</span></span><br><span class="line">    <span class="comment">#  requests:</span></span><br><span class="line">    <span class="comment">#    cpu: "500m"</span></span><br><span class="line">    <span class="comment">#    memory: "1024Mi"</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f filesystem.yaml</span><br></pre></td></tr></table></figure><h2 id="deployment直接使用"><a href="#deployment直接使用" class="headerlink" title="deployment直接使用"></a>deployment直接使用</h2><p>此deployment中的pod共享文件目录，即/var/lib/registry在三个pod中是都可以读写的。编排文件<code>registry.yaml</code>如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-registry</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line">        <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">registry:2</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line">        <span class="comment"># Configuration reference: https://docs.docker.com/registry/configuration/</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_ADDR</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">:5000</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_SECRET</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"Ple4seCh4ngeThisN0tAVerySecretV4lue"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">image-store</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        livenessProbe:</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            port:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">        readinessProbe:</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            port:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">image-store</span></span><br><span class="line"><span class="attr">        flexVolume:</span></span><br><span class="line"><span class="attr">          driver:</span> <span class="string">ceph.rook.io/rook</span></span><br><span class="line"><span class="attr">          fsType:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">          options:</span></span><br><span class="line"><span class="attr">            fsName:</span> <span class="string">myfs</span> <span class="comment"># name of the filesystem specified in the filesystem CRD.</span></span><br><span class="line"><span class="attr">            clusterNamespace:</span> <span class="string">rook-ceph</span> <span class="comment"># namespace where the Rook cluster is deployed</span></span><br><span class="line">            <span class="comment"># by default the path is /, but you can override and mount a specific path of the filesystem by using the path attribute</span></span><br><span class="line">            <span class="comment"># the path must exist on the filesystem, otherwise mounting the filesystem at that path will fail</span></span><br><span class="line">            <span class="comment">#path: /some/path/inside/cephfs</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f registry.yaml</span><br></pre></td></tr></table></figure><h2 id="通过pv及pvc使用"><a href="#通过pv及pvc使用" class="headerlink" title="通过pv及pvc使用"></a>通过pv及pvc使用</h2><h3 id="创建pv"><a href="#创建pv" class="headerlink" title="创建pv"></a>创建pv</h3><p>pv编排文件如下<code>pv.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cephfs-pv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  storageClassName:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  flexVolume:</span></span><br><span class="line"><span class="attr">    driver:</span> <span class="string">ceph.rook.io/rook</span></span><br><span class="line"><span class="attr">    fsType:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">    options:</span></span><br><span class="line"><span class="attr">      clusterNamespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">      fsName:</span> <span class="string">myfs</span></span><br><span class="line"><span class="attr">      path:</span> <span class="string">/some/bigdata/flex</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f pv.yaml</span><br></pre></td></tr></table></figure><h3 id="创建pvc"><a href="#创建pvc" class="headerlink" title="创建pvc"></a>创建pvc</h3><p>pvc编排文件如下<code>pvc.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pvc-nas</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  storageClassName:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f pvc.yaml</span><br></pre></td></tr></table></figure><h3 id="创建deployment"><a href="#创建deployment" class="headerlink" title="创建deployment"></a>创建deployment</h3><p>deployment编排文件如下<code>registry2.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-registry</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line"><span class="attr">  strategy:</span></span><br><span class="line"><span class="attr">    rollingUpdate:</span></span><br><span class="line"><span class="attr">      maxSurge:</span> <span class="number">25</span><span class="string">%</span></span><br><span class="line"><span class="attr">      maxUnavailable:</span> <span class="number">25</span><span class="string">%</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">RollingUpdate</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">kube-registry</span></span><br><span class="line">        <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_ADDR</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">:5000</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_SECRET</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">Ple4seCh4ngeThisN0tAVerySecretV4lue</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">registry:2</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">        livenessProbe:</span></span><br><span class="line"><span class="attr">          failureThreshold:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            port:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">            scheme:</span> <span class="string">HTTP</span></span><br><span class="line"><span class="attr">          periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">          successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">          timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        readinessProbe:</span></span><br><span class="line"><span class="attr">          failureThreshold:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">            port:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">            scheme:</span> <span class="string">HTTP</span></span><br><span class="line"><span class="attr">          periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">          successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">          timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line"><span class="attr">        terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - mountPath:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">image-store</span></span><br><span class="line"><span class="attr">      dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">      schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line"><span class="attr">      securityContext:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">image-store</span></span><br><span class="line"><span class="attr">        persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">          claimName:</span> <span class="string">pvc-nas</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f registry2.yaml</span><br></pre></td></tr></table></figure><ul><li><input checked="" disabled="" type="checkbox"> 注意：虽然pv和pvc写了大小，但是在此文件系统中可用大于此值，无法做限制。</li></ul>]]></content>
    
    <summary type="html">
    
      rook是云原生的存储解决方案
    
    </summary>
    
    
      <category term="k8s rook ceph" scheme="http://huaqiang.art/categories/k8s-rook-ceph/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="rook" scheme="http://huaqiang.art/tags/rook/"/>
    
      <category term="分布式存储" scheme="http://huaqiang.art/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>rook安装及使用ceph rbd</title>
    <link href="http://huaqiang.art/2020/02/10/rook-install/"/>
    <id>http://huaqiang.art/2020/02/10/rook-install/</id>
    <published>2020-02-10T13:00:01.000Z</published>
    <updated>2020-04-04T09:52:17.176Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul><li>默认安装好了kubernetes集群，版本大于1.10</li><li>k8s节点至少提供5G的容量安装软件<a id="more"></a></li></ul><h2 id="下载rook"><a href="#下载rook" class="headerlink" title="下载rook"></a>下载rook</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载，以1.0.5版本为例</span></span><br><span class="line">$ wget https://github.com/rook/rook/archive/v1.0.5.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">$ tar -xzvf v1.0.5.tar.gz</span><br></pre></td></tr></table></figure><h2 id="安装rook"><a href="#安装rook" class="headerlink" title="安装rook"></a>安装rook</h2><ol><li>安装相关组件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> rook-1.0.5/cluster/examples/kubernetes/ceph/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装common,rook在k8s中需要的role,serviceaccount等资源</span></span><br><span class="line">$ kubectl create -f common.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装operator，相当于rook的大脑，核心程序</span></span><br><span class="line">$ kubectl create -f operator.yaml</span><br></pre></td></tr></table></figure><ol start="2"><li>检查相关pod是否启动<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n rook-ceph get pod</span><br></pre></td></tr></table></figure></li></ol><h2 id="在rook创建ceph集群"><a href="#在rook创建ceph集群" class="headerlink" title="在rook创建ceph集群"></a>在rook创建ceph集群</h2><ol><li>修改目录下cluster-test.yaml文件，使其如下<code>hq-cluster.yaml</code>。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephCluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  cephVersion:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">ceph/ceph:v14.2.1-20190430</span></span><br><span class="line"><span class="attr">    allowUnsupported:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  dataDirHostPath:</span> <span class="string">/var/lib/rook</span></span><br><span class="line"><span class="attr">  mon:</span></span><br><span class="line"><span class="attr">    count:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">    allowMultiplePerNode:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  dashboard:</span></span><br><span class="line"><span class="attr">    enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  network:</span></span><br><span class="line"><span class="attr">    hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  rbdMirroring:</span></span><br><span class="line"><span class="attr">    workers:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">  storage:</span> <span class="comment"># cluster level storage configuration and selection</span></span><br><span class="line"><span class="attr">    useAllNodes:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    useAllDevices:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    deviceFilter:</span></span><br><span class="line"><span class="attr">    location:</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line"><span class="attr">    nodes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"node4"</span></span><br><span class="line"><span class="attr">      devices:</span> <span class="comment"># specific devices to use for storage can be specified for each node</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdb"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdc"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdd"</span></span><br><span class="line"><span class="attr">      config:</span> <span class="comment"># configuration can be specified at the node level which overrides the cluster level config</span></span><br><span class="line"><span class="attr">        storeType:</span> <span class="string">filestore</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"node5"</span></span><br><span class="line"><span class="attr">      devices:</span> <span class="comment"># specific devices to use for storage can be specified for each node</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdb"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdc"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdd"</span></span><br><span class="line"><span class="attr">      config:</span> <span class="comment"># configuration can be specified at the node level which overrides the cluster level config</span></span><br><span class="line"><span class="attr">        storeType:</span> <span class="string">filestore</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"node6"</span></span><br><span class="line"><span class="attr">      devices:</span> <span class="comment"># specific devices to use for storage can be specified for each node</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdb"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdc"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdd"</span></span><br><span class="line"><span class="attr">      config:</span> <span class="comment"># configuration can be specified at the node level which overrides the cluster level config</span></span><br><span class="line"><span class="attr">        storeType:</span> <span class="string">filestore</span></span><br></pre></td></tr></table></figure>此配置表示:</li></ol><ul><li>useAllNodes: false   不针对所有的节点，而是手动指定节点</li><li>useAllDevices: false  不选择所有空闲的磁盘，而是手动指定</li><li>nodes: 数组格式，指定node4上面的sdb,sdc,sdd三块盘和node5上sdb,sdc,sdd三块盘及node6上sdb,sdc,sdd</li><li>storeType: filestore ceph类型使用filestore</li></ul><ol start="2"><li><p>创建该<code>hq-cluster.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f hq-cluster.yaml</span><br></pre></td></tr></table></figure></li><li><p>检查相关组件是否启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -n rook-ceph</span><br><span class="line">NAME                                    READY   STATUS      RESTARTS   AGE</span><br><span class="line">rook-ceph-agent-2zxz4                   1/1     Running     1          60d</span><br><span class="line">rook-ceph-agent-hrj58                   1/1     Running     1          60d</span><br><span class="line">rook-ceph-agent-m5hns                   1/1     Running     0          60d</span><br><span class="line">rook-ceph-mgr<span class="_">-a</span>-84dcffc8f6-hwlcc        1/1     Running     0          12h</span><br><span class="line">rook-ceph-mon<span class="_">-a</span>-967c6dcbd-rtm74         1/1     Running     0          3d15h</span><br><span class="line">rook-ceph-mon-b-b56bcf68c-xkj49         1/1     Running     1          60d</span><br><span class="line">rook-ceph-mon-c-5b9984bccd-jz7fw        1/1     Running     0          57d</span><br><span class="line">rook-ceph-operator-68cb95fc7c-mvczx     1/1     Running     1          3d15h</span><br><span class="line">rook-ceph-osd-0-6cd844b7db-kc7p7        1/1     Running     1          60d</span><br><span class="line">rook-ceph-osd-1-fc784fb6d-nrvpx         1/1     Running     0          3d15h</span><br><span class="line">rook-ceph-osd-2-79cf8d88f6-crcw7        1/1     Running     1          60d</span><br><span class="line">rook-ceph-osd-3-5787545c8-5chm4         1/1     Running     0          3d15h</span><br><span class="line">rook-ceph-osd-4-76b64b8974-ffmnn        1/1     Running     1          60d</span><br><span class="line">rook-ceph-osd-5-99c99748-gk7pn          1/1     Running     0          3d15h</span><br><span class="line">rook-ceph-osd-6-5dbfdf6cb7-sqr2z        1/1     Running     0          4d14h</span><br><span class="line">rook-ceph-osd-7-568f65bf8d-w475v        1/1     Running     0          4d14h</span><br><span class="line">rook-ceph-osd-8-598b9565d5-qldtn        1/1     Running     0          4d14h</span><br><span class="line">rook-ceph-osd-prepare-node4-vqst4       0/2     Completed   0          12h</span><br><span class="line">rook-ceph-osd-prepare-node5-zplb2       0/2     Completed   0          12h</span><br><span class="line">rook-ceph-osd-prepare-node6-nkldv       0/2     Completed   1          12h</span><br><span class="line">rook-discover-4ddcl                     1/1     Running     2          60d</span><br><span class="line">rook-discover-gqcht                     1/1     Running     0          60d</span><br><span class="line">rook-discover-qvwbn                     1/1     Running     1          60d</span><br></pre></td></tr></table></figure></li></ol><h2 id="在k8s中创建storageclass供k8s使用"><a href="#在k8s中创建storageclass供k8s使用" class="headerlink" title="在k8s中创建storageclass供k8s使用"></a>在k8s中创建storageclass供k8s使用</h2><ol><li>当前文件中包含相关资源，直接创建即可</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f storageclass.yaml</span><br></pre></td></tr></table></figure><ol start="2"><li>检查sc是否创建成功</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get sc -n rook-ceph</span><br></pre></td></tr></table></figure><p>此时新创建的storageclass<code>rook-ceph-block</code>便可在k8s中使用了。</p><h2 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h2><ol><li>安装ceph-tools，可以执行ceph相关命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f toolbox.yaml </span><br><span class="line"></span><br><span class="line"><span class="variable">$kubectl</span> <span class="built_in">exec</span> -ti rook-ceph-tools-6544484c68-m64vz -n </span><br><span class="line">[....]$ ceph status</span><br><span class="line">  cluster:</span><br><span class="line">    id:     db4f6f7a-5606-4a7d-9eba-9b4901cd7a38</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum a,b,c (age 3d)</span><br><span class="line">    mgr: a(active, since 12h)</span><br><span class="line">    mds: myfs:1 &#123;0=myfs<span class="_">-a</span>=up:active&#125; 1 up:standby-replay</span><br><span class="line">    osd: 9 osds: 9 up (since 3d), 9 <span class="keyword">in</span> (since 3d)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   3 pools, 300 pgs</span><br><span class="line">    objects: 5.55k objects, 17 GiB</span><br><span class="line">    usage:   30 GiB used, 366 GiB / 396 GiB avail</span><br><span class="line">    pgs:     300 active+clean</span><br><span class="line"> </span><br><span class="line">  io:</span><br><span class="line">    client:   1.2 KiB/s rd, 5.7 KiB/s wr, 2 op/s rd, 0 op/s wr</span><br></pre></td></tr></table></figure></li><li>dashboard<br>在<code>cluster-test.yaml</code>有  dashboard选项，设置为true，则自动部署dashboard,查看dashboard登陆的svc为<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc -n rook-ceph |grep dashboard</span><br><span class="line">rook-ceph-mgr-dashboard        LoadBalancer   10.233.9.154    3.1.20.51     8443:32600/TCP      60d</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      rook是云原生的存储解决方案,
    
    </summary>
    
    
      <category term="k8s rook ceph" scheme="http://huaqiang.art/categories/k8s-rook-ceph/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="rook" scheme="http://huaqiang.art/tags/rook/"/>
    
      <category term="分布式存储" scheme="http://huaqiang.art/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>我为什么会被kubernetes圈粉</title>
    <link href="http://huaqiang.art/2019/08/16/whyk8s/"/>
    <id>http://huaqiang.art/2019/08/16/whyk8s/</id>
    <published>2019-08-16T13:37:20.000Z</published>
    <updated>2020-04-04T07:18:09.863Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>什么是云计算，对于云计算我们到底怎么理解的。是李彦宏说的新瓶装旧酒，还是马化腾说的还需1000年，或者是马云说的充满希望和信息？</p><a id="more"></a><h2 id="云计算的发展"><a href="#云计算的发展" class="headerlink" title="云计算的发展"></a>云计算的发展</h2><p>云计算已经说了几十年了，现在依然是IT人嘴里常提的一个词。至于什么是云计算，网上有很多概念，这里不做概念解释，而是通过自己的理解将其分为几个阶段（不探讨公有云）</p><ul><li><p>第一阶段 每个公司都有自己的数据中心，自己的计算资源，自己的网络资源，自己的存储资源，自己的IT管理模块。</p></li><li><p>第二阶段 云计算提出阶段，公司整合计算资源，网络资源，存储资源，使资源可以按需配置，灵活扩展。在这一阶段公司将资源池化，通过虚拟化技术、云计算管理界面可以在短时间内就绪一套基础环境，而不需要像第一阶段那样又一个冗长的采购审批流程。代表有vmware,openstack，其他各种私有云技术</p></li><li><p>第三阶段，云计算阶段，除了需要达到第二个阶段的资源整合外，还需包含丰富的服务自制理，弹性伸缩等，计算资源，存储资源，网络资源全部由使用者定义，我们再也不讨论运维，不知道是谁在运维，是什么在运维。</p></li><li><p>第四阶段，GOD cometh in that cloud，在我们还不知道我们需要什么的时候，他便为我们制造了一切。</p></li><li><input checked="" disabled="" type="checkbox"> <p>我们目前整处在第三阶段初期的变革之中，催生了DevOps,CICD,AIOPS,NOOPS,serverless等我们憧憬的东西。</p></li></ul><h2 id="云计算和放牛娃"><a href="#云计算和放牛娃" class="headerlink" title="云计算和放牛娃"></a>云计算和放牛娃</h2><h3 id="第一阶段到第二阶段"><a href="#第一阶段到第二阶段" class="headerlink" title="第一阶段到第二阶段"></a>第一阶段到第二阶段</h3><p>  小时候，每年暑假做的最多的一件事就是放牛。那时候每家都有一头水牛。牛的主要工作是耕地，当然需要时也会拉拉车，推推磨。没有经历的人可能不知道，其实牛并不幸苦，它干的活对我们人来说很牛X，但对它来说太小意思了，而且它的工作别说996，334都达不到。而且更多时候是我们在伺候这位牛爸爸。<br>  于是我们就想，能不能每个村共有一头牛，而不是每家都有一头牛，这样我们就爽啦。但是一头牛耕一个村的地还不把它累死。那我们能造一个累不死的超级牛吗？当然不能，我们不是造物主，得符合自然界客观规律。但是一个村有共有牛是个不错的想法，于是老王家就买了10头牛，创建了牛cloud。不想养牛的人，需要用牛的时候可以来租。从此每家的小孩子就不用放牛了，可以用这个时间来学习高科技了。如果我们把每家都理解成小企业，那么老王家就是公有云厂商，像AWS，Azure，阿里云；如果我们把这个村理解成一个企业，那么老王家就是这个公司的IT部门。</p><h3 id="第二阶段到第三阶段"><a href="#第二阶段到第三阶段" class="headerlink" title="第二阶段到第三阶段"></a>第二阶段到第三阶段</h3><p>  到上面大家可能以为就万事大吉了，那你可能想错了，第一个问题：每年春耕的好日子就那么几天，过了那几天耕地下种子就会影响来年的收成，所以每年到这个时候，大家都来抢牛，为了保障能使用上牛，每家申请都是按天的，即使一天就耕那么一小时，有时候申请的牛病了这一天就耽误了。第二个问题：以前小王放牛，一头牛好放，二头牛也能放，但是10头牛就不是那么好放了。<br>  于是我们又想，老王家能不能雇10几个耕地者，这样谁家来申请就不在申请耕牛了，而是申请耕地服务，这样大家就不在看着牛了，而是考虑自己家的地有没有耕，地耕完立马释放了牛。这种方式就可以细粒度的切分资源，进一步提高牛的使用率。至于小王放牛，以前牵着放，现在可以用工具把大批草料弄回家去喂牛。从此每家都不用在那几天抢牛了，小王也不用担心放牛了。<br>  如果牛是操作系统，那么现在牛耕与李家这个事可以理解成容器，牛耕与李家也不绑定是哪头，这头牛不行，就用下一头牛，而且李家也不用担心这头牛不行，或者耕一半生病了，耕地者自然会调度和切换牛。牛耕地运行时就是内存、CPU资源了，每家只需申请牛耕地运行时。小王喂牛方式的改变就是现在运维方式的改变，以前小王和牛朝夕相处，现在牛栏里关的牛是啥颜色可能都不知道，他只需割草喂牛。</p><h3 id="第三阶段到第四阶段"><a href="#第三阶段到第四阶段" class="headerlink" title="第三阶段到第四阶段"></a>第三阶段到第四阶段</h3><p>  到了上面大家可能又认为万事大吉了，那你又错了，牛会生病，耕地者会生病，大家都在学习高科技，小王的孩子小小王不想学他爸爸再和牛有关系了。不过好在学习高科技那些孩子长大了，创造了不吃草，会自己耕地的牛。</p><h3 id="第四阶段"><a href="#第四阶段" class="headerlink" title="第四阶段"></a>第四阶段</h3><p>  小小小小王抬头看了一眼表，刚好12:00。回头看了下自己工位，一份8个腊八蒜，24片肥肠的腊八蒜炒肥肠放在了桌子上。不知道哪儿来的，反正就在那里。</p><ul><li><input checked="" disabled="" type="checkbox"> 在第二阶段到第三阶段中，牛，小王，耕地者，申请耕地的人，他们之间由谁来协调，谁来管理。目前我想比较出色的就是kubernetes了。</li></ul>]]></content>
    
    <summary type="html">
    
      如何理解云计算
    
    </summary>
    
    
      <category term="k8s" scheme="http://huaqiang.art/categories/k8s/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="docker" scheme="http://huaqiang.art/tags/docker/"/>
    
      <category term="云计算" scheme="http://huaqiang.art/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Service mesh 之 初探（一）</title>
    <link href="http://huaqiang.art/2019/07/07/ServiceMesh/"/>
    <id>http://huaqiang.art/2019/07/07/ServiceMesh/</id>
    <published>2019-07-07T12:37:20.000Z</published>
    <updated>2020-04-04T07:35:12.871Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Service mesh在云原生中是不可缺少的一环，幸运的是kubernetes环境下的service mesh解决方案不像我们想象的那么麻烦。</p><a id="more"></a><h3 id="提出"><a href="#提出" class="headerlink" title="提出"></a>提出</h3><p>微服务架构最早只在以架构师为主的少数派群体中谈论，随着容器技术的爆发式发展，微服务架构再次引起了更多人的注意。在微服务架构中，各个微服务之间的流量控制、路由分发、请求监控、高质量的网络传输一直都是采用侵入式的设计思想，但是这种侵入式的开发框架会导致开发工作量的大幅增加。非侵入式的Service Mesh技术的出现，犹如一股春风迎面吹来。</p><p>Service Mesh最早是Buoyant公司提出，该公司由两个Twitter跳槽的工程创办，并且开发了第一个Service Mesh项目linkerd，<br>2016年9月29日Buoyant CEO Willian Morgan演讲时第一次公开使用Service Mesh：</p><blockquote><p>原文：A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.</p></blockquote><blockquote><p>翻译：服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求可以在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但应用程序不需要知道它们的存在。</p></blockquote><p>2017年初，随着linkerd的传入，Service Mesh进入国内技术社区。<br>国内最早翻译为“服务啮合层”，但是比较拗口，后来逐渐改为“服务网格”</p><h3 id="理解service-Mesh"><a href="#理解service-Mesh" class="headerlink" title="理解service Mesh"></a>理解service Mesh</h3><p>考虑这样一个问题，如果在服务之间处理服务发现、负载均衡、超时、重试等机制该如何处理？</p><ol><li>我们首先想到的应该是每个微服务自己处理，由开发人员开发相关代码，如下图：</li></ol><img src="/assets/img/servicemesh1-1.jpg" width="75%"><ol start="2"><li>上面架构解决了我们的需求，但是每次开发除了业务逻辑外，还处理网络控制，这极大的增加了工作量，甚至有时网络控制这段逻辑比业务代码还要难。于是就有了一些框架，所有服务使用统一的类库进行通讯，比如Netflix oss套件，Spring Cloud框架。这样，开发人员只需少量的代码，甚至几个注释就能搞定，如下图：</li></ol><img src="/assets/img/servicemesh1-2.jpg" width="75%"><ol start="3"><li>在一段时间上面第二种结构满足了微服务架构的需求，但是其对框架的依赖较大，而且不能跨语言。真真的微服务架构，应该是service A无需关注service B是何种开发语言的。随着service mesh的提出，出现了以下架构：</li></ol><img src="/assets/img/servicemesh1-3.jpg" width="75%"><p>在上面架构图中，把微服务之间的交互抽象出一层，做为基础设施层，这样代码的开发完全不需关注网络控制，如服务发现、负责均衡、超时重试等，也不需要每个微服务使用同一种开发语言或者使用同一种开发框架。</p><p>Service Mesh的定义：Service Mesh是一个用于处理服务与服务之间通信的基础架构设施层。</p><ul><li><input checked="" disabled="" type="checkbox"> 其实这种抽象分层的处理思路早在OSI七层模型中就由体现。在我们解决复杂的逻辑是不妨多采用这种思路处理问题。</li></ul>]]></content>
    
    <summary type="html">
    
      服务治理在kubernetes中是非常重要的一块
    
    </summary>
    
    
      <category term="k8s" scheme="http://huaqiang.art/categories/k8s/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="docker" scheme="http://huaqiang.art/tags/docker/"/>
    
      <category term="service mesh" scheme="http://huaqiang.art/tags/service-mesh/"/>
    
  </entry>
  
  <entry>
    <title>prometheus 配置钉钉告警</title>
    <link href="http://huaqiang.art/2019/05/28/alertmanager/"/>
    <id>http://huaqiang.art/2019/05/28/alertmanager/</id>
    <published>2019-05-28T12:30:20.000Z</published>
    <updated>2020-04-04T10:01:08.095Z</updated>
    
    <content type="html"><![CDATA[<p>prometheus的alertmanager本身不支持直接使用钉钉告警的方式，若配置钉钉告警需要webhook插件做为组件。</p><a id="more"></a><h3 id="安装钉钉告警webhook插件"><a href="#安装钉钉告警webhook插件" class="headerlink" title="安装钉钉告警webhook插件"></a>安装钉钉告警webhook插件</h3><p>由于我的prometheus和alertmanager都安装在kubernetes里面，所以钉钉插件也安装在k8s平台里面。若需要其他安装方式，可以参考<br><a href="https://github.com/timonwong/prometheus-webhook-dingtalk">钉钉插件github仓库</a></p><ul><li>vim dingtalk-alert-deployment.yml</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: dingtalk-alert</span><br><span class="line">  name: dingtalk-alert</span><br><span class="line">  namespace: monitor</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: dingtalk-alert</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: dingtalk-alert</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: timonwong&#x2F;prometheus-webhook-dingtalk</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;bin&#x2F;prometheus-webhook-dingtalk</span><br><span class="line">        - --ding.profile&#x3D;webhook1&#x3D;https:&#x2F;&#x2F;oapi.dingtalk.com&#x2F;robot&#x2F;send?access_token&#x3D;da1cc37cd155f73112bcbf4aa4be49c8c400786f1b38908a15fa1e9be0eee51</span><br><span class="line">        - --template.file&#x3D;&#x2F;usr&#x2F;share&#x2F;prometheus-webhook-dingtalk&#x2F;template&#x2F;default.tmpl</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: dingtalk-alert</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8086</span><br><span class="line">          name: service</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 512Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 128Mi</span><br><span class="line">        terminationMessagePath: &#x2F;dev&#x2F;termination-log</span><br><span class="line">        terminationMessagePolicy: File</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;usr&#x2F;share&#x2F;prometheus-webhook-dingtalk&#x2F;template&#x2F;default.tmpl</span><br><span class="line">          name: dingtalk-tmpl</span><br><span class="line">          subPath: default.tmpl</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      volumes:</span><br><span class="line">      - configMap:</span><br><span class="line">          name: dingtalk-alert-configmap</span><br><span class="line">        name: dingtalk-tmpl</span><br></pre></td></tr></table></figure><ul><li><input checked="" disabled="" type="checkbox"> 注意： –ding.profile指定钉钉机器人的url，其中webhook1为自定义名称，在配置alertmanager规则中指定webhook时会使用</li></ul><ul><li><input checked="" disabled="" type="checkbox"> 注意：–template.file指定发送告警模版文件</li></ul><ul><li>[x]注意：–ding.profile后钉钉机器人url不可有引号，不然会报404错误，非k8s安装时需要加引号</li></ul><ul><li>vim dingtalk-configmap.yml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  default.tmpl: |</span><br><span class="line">    &#123;&#123; define &quot;__subject&quot; &#125;&#125;[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;] &#123;&#123; .GroupLabels.SortedPairs.Values | join &quot; &quot; &#125;&#125; &#123;&#123; if gt (len .CommonLabels) (len .GroupLabels) &#125;&#125;(&#123;&#123; with .CommonLabels.Remove .GroupLabels.Names &#125;&#125;&#123;&#123; .Values | join &quot; &quot; &#125;&#125;&#123;&#123; end &#125;&#125;)&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">    &#123;&#123; define &quot;__alertmanagerURL&quot; &#125;&#125;&#123;&#123; .ExternalURL &#125;&#125;&#x2F;#&#x2F;alerts?receiver&#x3D;&#123;&#123; .Receiver &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">    &#123;&#123; define &quot;__text_alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line">    **告警**</span><br><span class="line">    &#123;&#123; range .Annotations.SortedPairs &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">    &#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">    **标签**</span><br><span class="line">    &#123;&#123; range .Labels.SortedPairs &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">    &#123;&#123; end &#125;&#125;</span><br><span class="line">    **Source:** **http:&#x2F;&#x2F;grafana.monitor.bj.univer.top&#x2F;d&#x2F;xLrfYirmk&#x2F;a-li-yun-gao-jing?orgId&#x3D;1**</span><br><span class="line"></span><br><span class="line">    &#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">    &#123;&#123; define &quot;ding.link.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">    &#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;#### \[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;\] **[&#123;&#123; index .GroupLabels &quot;alertname&quot; &#125;&#125;](&#123;&#123; template &quot;__alertmanagerURL&quot; . &#125;&#125;)**</span><br><span class="line">    &#123;&#123; template &quot;__text_alert_list&quot; .Alerts.Firing &#125;&#125;</span><br><span class="line">    &#123;&#123; end &#125;&#125;</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2019-05-13T07:15:10Z</span><br><span class="line">  labels:</span><br><span class="line">    app: dingtalk-alert</span><br><span class="line">  name: dingtalk-alert-configmap</span><br><span class="line">  namespace: monitor</span><br></pre></td></tr></table></figure></li><li>vim dingtalk-service.yml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2019-05-13T07:15:10Z</span><br><span class="line">  labels:</span><br><span class="line">    app: dingtalk-alert</span><br><span class="line">  name: dingtalk-alert-svc</span><br><span class="line">  namespace: monitor</span><br><span class="line">  resourceVersion: &quot;31476279&quot;</span><br><span class="line">  selfLink: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;monitor&#x2F;services&#x2F;dingtalk-alert-svc</span><br><span class="line">  uid: d81b6783-754e-11e9-8566-00163e10fec4</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 172.19.1.47</span><br><span class="line">  externalTrafficPolicy: Cluster</span><br><span class="line">  ports:</span><br><span class="line">  - name: service</span><br><span class="line">    nodePort: 31221</span><br><span class="line">    port: 8060</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8060</span><br><span class="line">  selector:</span><br><span class="line">    app: dingtalk-alert</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure></li></ul><h3 id="修改alertmanager配置"><a href="#修改alertmanager配置" class="headerlink" title="修改alertmanager配置"></a>修改alertmanager配置</h3><ul><li>alertmanager增加webhook选项，指定钉钉插件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">alertmanager.yml: |</span><br><span class="line">  global:</span><br><span class="line">      resolve_timeout: 5m</span><br><span class="line">  receivers:</span><br><span class="line">  - name: webhook</span><br><span class="line">    webhook_configs:</span><br><span class="line">    - url: http:&#x2F;&#x2F;dingtalk-alert-svc:8060&#x2F;dingtalk&#x2F;ops&#x2F;send</span><br><span class="line">      send_resolved: true</span><br><span class="line">  route:</span><br><span class="line">    group_interval: 5m</span><br><span class="line">    group_wait: 10s</span><br><span class="line">    receiver: webhook</span><br><span class="line">    repeat_interval: 3h</span><br></pre></td></tr></table></figure><h3 id="整体结构如下"><a href="#整体结构如下" class="headerlink" title="整体结构如下"></a>整体结构如下</h3><img src="/assets/img/altermanager.jpg" width="75%"></li></ul>]]></content>
    
    <summary type="html">
    
      alertmanager是prometheus中的告警模块，可以支持微信、钉钉等主流应用。
    
    </summary>
    
    
      <category term="k8s" scheme="http://huaqiang.art/categories/k8s/"/>
    
    
      <category term="k8s" scheme="http://huaqiang.art/tags/k8s/"/>
    
      <category term="prometheus" scheme="http://huaqiang.art/tags/prometheus/"/>
    
      <category term="监控" scheme="http://huaqiang.art/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>docker中的top命令</title>
    <link href="http://huaqiang.art/2019/05/23/top/"/>
    <id>http://huaqiang.art/2019/05/23/top/</id>
    <published>2019-05-23T12:37:20.000Z</published>
    <updated>2020-04-04T07:16:14.242Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>客户交流中被问到的两个问题<br>1.在docker中运行top命令能否看到宿主机的内存CPU信息？<br>2.op能看到容器外面宿主机的进程吗？</p><a id="more"></a><h4 id="提问：在docker中运行top命令能否看到宿主机的内存CPU信息？"><a href="#提问：在docker中运行top命令能否看到宿主机的内存CPU信息？" class="headerlink" title="提问：在docker中运行top命令能否看到宿主机的内存CPU信息？"></a>提问：在docker中运行top命令能否看到宿主机的内存CPU信息？</h4><p>回答这个问题之前我们首先想以下linux系统中的/proc目录是干什么的</p><p>/proc是个伪文件系统，存在于内存之中而不是硬盘上。通过它可以和内核内部数据结构进行交互，获取 有关进程的有用信息。<br>/proc中会有以下文件:</p><ul><li>/proc/cpuinfo - CPU 的信息(型号, 家族, 缓存大小等)</li><li>/proc/meminfo - 物理内存、交换空间等的信息</li><li>/proc/mounts - 已加载的文件系统的列表</li><li>/proc/devices - 可用设备的列表</li><li>/proc/filesystems - 被支持的文件系统</li><li>/proc/modules - 已加载的模块</li><li>/proc/version - 内核版本</li><li>/proc/cmdline - 系统启动时输入的内核命令行参数</li><li>/proc/{pid} - 进程信息</li></ul><p>top正是通过/proc来获取当前内存、CPU信息的。dock er启动的容器共享操作系统内核，在容器启动的时候会挂载部分/proc里面的文件，能否通过top在docker中看到内存和CPU信息，主要看有没有挂载这些文件。</p><p>那么问题又来了，需要手动挂载这些文件吗？一般来说不需要，挂载内容的多少一般和镜像有关。一般的redhat/ubuntu镜像都是会挂载内存CPU信息的，精简的dokcer镜像信息会少些，有时top得到的信息不全面。</p><h4 id="另外一个问题，top能看到容器外面宿主机的进程吗？"><a href="#另外一个问题，top能看到容器外面宿主机的进程吗？" class="headerlink" title="另外一个问题，top能看到容器外面宿主机的进程吗？"></a>另外一个问题，top能看到容器外面宿主机的进程吗？</h4><p>经过上面分析top看到信息的多少取决于/proc里面内容，由于pid 命名空间的隔离，宿主机的pid信息不会被启动容器挂载，所以看不到容器外宿主机进程。</p><ul><li><input disabled="" type="checkbox"> free -m命令原理和top类似</li></ul>]]></content>
    
    <summary type="html">
    
      docker中执行top命令能否看到宿主机内存CPU信息
    
    </summary>
    
    
      <category term="docker" scheme="http://huaqiang.art/categories/docker/"/>
    
    
      <category term="linux" scheme="http://huaqiang.art/tags/linux/"/>
    
      <category term="docker" scheme="http://huaqiang.art/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>理解系统中的cache &amp; buffer</title>
    <link href="http://huaqiang.art/2019/05/21/buffer_cache/"/>
    <id>http://huaqiang.art/2019/05/21/buffer_cache/</id>
    <published>2019-05-21T12:37:20.000Z</published>
    <updated>2020-04-04T10:00:36.814Z</updated>
    
    <content type="html"><![CDATA[<p>在linux系统优化中，我们经常看到cache/buffer，但是什么是cache,什么是buffer呢，他们之间有没有区别？</p><a id="more"></a><p>从字面意思来看，cache是缓存，buffer是缓冲。这里假设有两个设备，分别叫A和B，由于制作工艺的差别，A的处理速度远远大于B。假设A和B在接口速度上有一定的差别，A接口速度为10M/s,B接口速度为5M/s.现在B中有件事需要A处理，命名为B<sub>1</sub>， 大小为10M，如下图所示:</p><p>A&lt;————-&gt;B(B<sub>1</sub>)</p><p>那么在处理这个事件会出现这种情况，1.A拿到B<sub>1</sub>需要2s，因为B的接口只为5M/s；2.同样A处理完还给B也需要2s。在这个过程中A一半的时间都在等待传输上。</p><p>若何优化这个过程呢，我们可以在A和B之间加一层：</p><p>A&lt;—–&gt;[a——–b]——&gt;B(B<sub>1</sub>,B<sub>2</sub>)</p><p>a的接口速度接近A，b的接口速度至少为B。那么</p><ul><li><p>在处理完B<sub>1</sub>后再处理B<sub>2</sub>，A就可以直接从a拿数据了，若后面还有B<sub>3</sub>，B<sub>4</sub>，B<sub>n</sub>需要处理，这将会大大节省时间，这个主要是读的操作就是是缓存，即cache的理解；</p></li><li><p>以上过程中我们不能忽略了A处理完B<sub>1</sub>往B写的过程。A处理完可以直接写入[a–b]，速度提升了，但不会立刻写到B，在处理完B<sub>2</sub>,B<sub>3</sub> …B<sub>n</sub>之后一起写入B，避免了对B频繁操作。这个主要是写的操作就是缓冲，即buffer的理解；</p></li></ul><p>一张图描述如下：</p><img src="/assets/img/buffer.jpg" width="75%" height="50%"><p>网上有两个有意思的例子：</p><ul><li><p>假设某地发生了自然灾害（比如地震），居民缺衣少食，于是派救火车去给若干个居民点送水。<br>救火车到达第一个居民点，开闸放水，老百姓就拿着盆盆罐罐来接水。<br>假如说救火车在一个居民点停留100分钟放完了水，然后重新储水花半个小时，再开往下一个居民点。这样一个白天来来来回回的，也就是4-5个居民点。<br>但我们想想，救火车是何等存在，如果把水龙头完全打开，其强大的水压能轻易冲上10层楼以上， 10分钟就可以把水全部放完。但因为居民是拿盆罐接水，100%打开水龙头那就是给人洗澡了，所以只能打开一小部分（比如10%的流量）。但这样就降低了放水的效率（只有原来的10%了），10分钟变100分钟。<br>那么，我们是否能改进这个放水的过程，让救火车以最高效率放完水、尽快赶往下一个居民点呢？<br>方法就是：在居民点建蓄水池。<br>救火车把水放到蓄水池里，因为是以100%的效率放水，10分钟结束然后走人。居民再从蓄水池里一点一点的接水。<br>我们分析一下这个例子，就可以知道Cache的含义了。<br>救火车要给居民送水，居民要从救火车接水，就是说居民和救火车之间有交互，有联系。<br>但救火车是“高速设备”，居民是“低速设备”，低速的居民跟不上高速的救火车，所以救火车被迫降低了放水速度以适应居民。<br>为了避免这种情况，在救火车和居民之间多了一层“蓄水池（也就是Cache）”，它一方面以100%的高效和救火车打交道，另一方面以10%的低效和居民打交道，这就解放了救火车，让其以最高的效率运行，而不被低速的居民拖后腿，于是救火车只需要在一个居民点停留10分钟就可以了。</p><blockquote><p>从以上例子可以看出，所谓Cache，就是“为了弥补高速设备和低速设备之间的矛盾”而设立的一个中间层。因为在现实里经常出现高速设备要和低速设备打交道，结果被低速设备拖后腿的情况。</p></blockquote></li><li><p>比如说吐鲁番的葡萄熟了，要用大卡车装葡萄运出去卖<br>果园的姑娘采摘葡萄，当然不是前手把葡萄摘下来,后手就放到卡车上，而是需要一个中间过程“箩筐”：摘葡萄→放到箩筐里→把箩筐里的葡萄倒入卡车。<br>也就是说，虽然最终目的是“把葡萄倒入卡车”，但中间必须要经过“箩筐”的转手，这里的箩筐就是Buffer。</p><blockquote><p>从以上例子可以看出，所谓buffer,就是是“暂时存放物品的空间”。它的引入是为了减小短期内突发I/O的影响，起到流量整形的作用。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      cache/buffer,系统优化必不可少的部分
    
    </summary>
    
    
      <category term="操作系统" scheme="http://huaqiang.art/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="linux" scheme="http://huaqiang.art/tags/linux/"/>
    
      <category term="概念" scheme="http://huaqiang.art/tags/%E6%A6%82%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>灾备的终极目标</title>
    <link href="http://huaqiang.art/2019/05/17/it/"/>
    <id>http://huaqiang.art/2019/05/17/it/</id>
    <published>2019-05-17T14:37:20.000Z</published>
    <updated>2020-04-04T07:37:51.544Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是灾备"><a href="#什么是灾备" class="headerlink" title="什么是灾备"></a>什么是灾备</h2><p>灾备主要分为三个发展阶段：</p><ul><li>整个灾备行业的起源应该是在70年代，当时主要关注的是IT系统数据、主要做的便是数据备份；<a id="more"></a></li><li>随着科技发展，IT备份发展到了灾难恢复规划，也就是DRP阶段，这一阶段不仅仅是数据备份了，还包括应急预案、灾备中心管理等；</li><li>再后来，人们通过业务连续性来衡量灾备的目标，也就是从DRP阶段到BCP阶段，在预案管理、灾备数据中心管理之上再加上面向业务的决策、公关等。<blockquote><p>总结下：第一阶段就是数据备份，工程师就可以干的；第二阶段需要建设灾备数据中心，灾备架构设计等，这个就需要至少IT负责人才能干；第三阶段涉及到业务，包括灾难发生后的各种应急预案，危机公关等，这个至少需要CXO以上级别参与才能办的到。</p></blockquote></li></ul><h2 id="RTO-RPO"><a href="#RTO-RPO" class="headerlink" title="RTO/RPO"></a>RTO/RPO</h2><ul><li><p>RTO：Recovery Time Objective,是指灾难发生后，从IT系统宕机导致业务停顿之时开始，到IT系统恢复至可以支持各部门运作、恢复运营之时，此两点之间的时间段。</p></li><li><p>RPO：Recovery Point Objective,是指灾难发生后，容灾系统能把数据恢复到灾难发生前时间点的数据。是衡量灾难发生后会丢失多少生产数据的指标。可简单的描述为设施能容忍的最大数据丢失量。</p></li></ul><blockquote><p>RPO衡量的是IT系统丢失的数据量（通过时间衡量）；RTO衡量的是IT系统不可用时间，现在也有业务RTO说法，指的是业务系统不可用时间（发生灾难业务系统不可用到下一次可用时间）</p></blockquote><ul><li><input checked="" disabled="" type="checkbox"> 使RTO和RPO无限趋向于0，是灾备的终极目标！</li></ul><h2 id="怎么做灾备"><a href="#怎么做灾备" class="headerlink" title="怎么做灾备"></a>怎么做灾备</h2><p>灾备怎么做？个人认为还是从第一节的三个角色给出建议。如果您是一个系统工程师或者数据库管理员，您的第一要务便是备份，永远记住不断向领导提备份重要性，做任何变更前第一件事就是备份。如果您是个IT负责人，您的第一要务就是数据安全，工程师的备份可能无法满足您对数据中心数据安全的需求，那么您一定得考虑容灾，容灾做成什么程度取决于您的预算和RPO/RTO要求。如果您是公司CEO，而您公司的业务系统承载了你们公司核心业务，那么您必须得过问你们数据中心业务系统的容灾，因为这可能影响你们公司的生死存亡。</p><p>这里对于灾备分为备份和容灾两部分：</p><ul><li>备份：备份主要考虑两点，一个是备份工具选择；另外一个就是备份计划制定。备份计划除了临时备份，一定得考虑周期性，备份工具可选择较多，以下举例几种</li></ul><table><thead><tr><th>备份工具</th><th>使用场景</th></tr></thead><tbody><tr><td>acronis</td><td>一款俄罗斯的备份工具，功能强大，基本能备份任何系统，甚至android系统</td></tr><tr><td>veeam</td><td>用于备份vmware和hyper-v,无需vm中安装Agent,备份恢复速度较快</td></tr><tr><td>NBU</td><td>赛门铁克企业级备份工具，稳定耐用，适合中大型企业，不过比较贵</td></tr><tr><td>BE</td><td>赛门铁克企业级备份工具，比NBU弱一些，适合3-100台服务器的中型企业</td></tr><tr><td>Amanda</td><td>最早出现的开源备份软件,通过系统命令执行备份，免费使用，也可以选择其服务版本zmanda</td></tr><tr><td>Bacula</td><td>开源的跨平台网络备份工具，它提供了基于企业级的客户端/服务器的备份恢复解决方案,也有商业版本，可提供操作界面</td></tr><tr><td>Asigra</td><td>无代理备份工具，物理机虚机均不需要代理（在同一个子网不需要输入用户名密码就可以扫描到其他主机目录，相当牛逼），使用需要硬件key</td></tr><tr><td>CommVault</td><td>没用过，也是个很给力的备份工具</td></tr></tbody></table><ul><li>容灾：容灾主要考虑三点，第一是容灾数据中心选择；第二是数据复制工具选择；第三是DRP，即灾难恢复计划。容灾主要讲究的是解决方案，但是第二个数据复制技术和工具选择是灵魂，以下列举几个感觉不错的容灾工具</li></ul><table><thead><tr><th>容灾工具</th><th>使用场景</th></tr></thead><tbody><tr><td>SRM</td><td>vmware自带解决方案，价格合适，RPO分钟级，RTO分钟级，无需安装Agent</td></tr><tr><td>Zerto</td><td>vmware、hyper-v解决方案，可以支持到AWS，Azure公有云灾备，CDP技术，RPO秒级，RTO分钟级别，无需安装Agent</td></tr><tr><td>飞康</td><td>CDP技术，存储级别解决方案，对带宽要求较大，RPO秒级、RTO秒级</td></tr><tr><td>Double-Take</td><td>OS级别解决方案，需要安装Agent，RPO秒级，RTO分钟级（测试有时是小时级别）</td></tr><tr><td>ARCserver</td><td>mysql,oracle,sqlserver解决方案，需要安装Agent，RPO秒级，RTO秒级</td></tr><tr><td>英方</td><td>和double-take类似</td></tr><tr><td>OceanMirror</td><td>国产软件，类似ARCserver，比ARCserver便宜</td></tr><tr><td>DTS</td><td>阿里云数据库灾备解决方案</td></tr><tr><td>Dataguard</td><td>oracle数据库容灾解决方案</td></tr><tr><td>AB复制</td><td>mysql容灾解决方案</td></tr></tbody></table><blockquote><p>在实际项目中，容灾备份很多时候在规划中，直到出现一次问题后才提上日程。做为一个专业的IT负责人应该把风险在出问题之前解决掉，而不是事后补救。</p></blockquote><h2 id="未来灾备方向"><a href="#未来灾备方向" class="headerlink" title="未来灾备方向"></a>未来灾备方向</h2><p>我们之前考虑容灾的数据复制自下而上分为，存储级别（飞康、vplex），hypervisor级别(zerto、SRM)，OS级别（DT、英方），软件级别（OM、ARCserver、DG)。主要解决的冲突为，硬件故障，操作系统故障，软件故障，业务数据丢失（分为结构化和非结构化数据）等。现在比较火的是容器技术和公有云，容积技术确实适合搭建未来IT所需的超级计算集群。</p><ol><li>由于计算集群搭建，云的概念越来越普及，硬件级别故障，os级别故障已经在云计算架构设计中解决了，不需对单个业务系统再做容灾保护。</li><li>在计算集群中非结构化数据倾向存于分布式存储，而分布式存储在设计时便考虑了容灾的特性。所以未来对非结构化数据容灾将越来越少。</li><li>结构化数据存储，对非关系型数据库需求增大，关系型数据库需求逐渐减小。</li></ol><blockquote><p>所以，个人认为未来灾备重心应该主要是在数据中心级别的分布式存储或分布式数据库架构设计上，部分在关系型数据库上。</p></blockquote>]]></content>
    
    <summary type="html">
    
      灾备是一个容易忽略的重要板块
    
    </summary>
    
    
      <category term="IT理念" scheme="http://huaqiang.art/categories/IT%E7%90%86%E5%BF%B5/"/>
    
    
      <category term="概念" scheme="http://huaqiang.art/tags/%E6%A6%82%E5%BF%B5/"/>
    
      <category term="灾备" scheme="http://huaqiang.art/tags/%E7%81%BE%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>静态博客之hexo</title>
    <link href="http://huaqiang.art/2018/05/18/hexo/"/>
    <id>http://huaqiang.art/2018/05/18/hexo/</id>
    <published>2018-05-18T14:37:20.000Z</published>
    <updated>2020-04-04T09:52:02.757Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个测试博客,若想知道更多hexo信息，请点击以下Quick Start中相关链接。</p><a id="more"></a><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个测试博客,若想知道更多hexo信息，请点击以下Quick Start中相关链接。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
